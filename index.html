<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Face Liveliness Check</title>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@latest"></script>
    <script src="https://cdn.jsdelivr.net/npm/face-api.js"></script>
    <style>
        /* style.css */
        video {
            border: 1px solid #ddd;
        }

        #result {
            padding: 10px;
            font-weight: bold;
        }
    </style>
</head>

<body>
    <video id="video" autoplay muted width="640" height="480"></video>
    <div id="result"></div>
    <script>import * as tf from '@tensorflow/tfjs';

        import * as faceapi from 'face-api.js';



        async function checkLiveliness(videoElement) {

            // Load the face detection and landmark localization model

            const model = await faceapi.loadFaceLandmarkModel('path/to/your/model');



            // Set up video stream

            const video = videoElement;

            const stream = await navigator.mediaDevices.getUserMedia({ video: true });

            video.srcObject = stream;



            // Start video capturing and processing

            video.play();

            const intervalId = setInterval(async () => {

                const frame = await tf.browser.toTensor(video);

                const detections = await faceapi.detectAllFaces(frame, new faceapi.SsdMobilenetv2Options({ minConfidence: 0.5 }))

                    .withFaceLandmarks();



                if (detections.length > 0) {

                    // Extract facial landmarks

                    const landmarks = detections[0].landmarks;



                    // Calculate ellipse and perpendicular line

                    const ellipseParams = fitEllipse(landmarks);

                    const perpendicularLine = calculatePerpendicularLine(ellipseParams);



                    // Analyze facial features

                    const eyeBlinks = analyzeEyeBlinks(landmarks);

                    const mouthMovements = analyzeMouthMovements(landmarks);

                    const noseMovements = analyzeNoseMovements(landmarks, ellipseParams);



                    // Combine checks and return result

                    const isLive = combineChecks(eyeBlinks, mouthMovements, noseMovements);

                    console.log('Liveliness:', isLive); // Log the result for debugging

                    clearInterval(intervalId); // Stop the interval if a result is obtained

                }

            }, 1000); // Adjust the interval as needed for real-time performance

        } </script>
</body>

</html>